{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('/Users/patrick/PycharmProjects/decision-trees/data/pa3_train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "train_features = train.drop('class', axis=1)\n",
    "train_labels = train['class']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_gini(pos_count, neg_count):\n",
    "    gini = 1 - (pos_count/(pos_count + neg_count))**2 - (neg_count/(pos_count+neg_count))**2\n",
    "    return gini\n",
    "\n",
    "def get_split_prob(pos_count, neg_count, total_count):\n",
    "    prob = (pos_count + neg_count)/total_count\n",
    "    return prob\n",
    "\n",
    "def get_split_benefit(feature, labels):\n",
    "    # Get total counts for positive and negative classes in dataset\n",
    "    pos_count = sum(labels)\n",
    "    neg_count = len(labels) - pos_count\n",
    "    total_count = len(labels)\n",
    "    \n",
    "    # Calculate initial uncertainty\n",
    "    initial_u = get_gini(pos_count, neg_count)\n",
    "    \n",
    "    # Create list of tuples with class label and feature value for each observation\n",
    "    # i.e. (1,1) represents class label == 1 and feature label == 1\n",
    "    zipped = list(zip(labels, feature))\n",
    "    \n",
    "    # Create dictionary with counts of tuples for each possible class label and feature \n",
    "    # value pair\n",
    "    label_value_count = dict(Counter(element for element in zipped))\n",
    "    \n",
    "    # Get counts for positive and negative class in each branch after split\n",
    "    # Left count in positive class ('class' == 1)\n",
    "    if (1,1) in label_value_count:\n",
    "        left_pos = label_value_count[(1,1)]\n",
    "    else:\n",
    "        left_pos = 0\n",
    "    # Left count in negative class ('class' == 0)    \n",
    "    if (0,1) in label_value_count:\n",
    "        left_neg = label_value_count[(0,1)]\n",
    "    else:\n",
    "        left_neg = 0\n",
    "    # Right count in positive class ('class' == 1)\n",
    "    if (1,0) in label_value_count:\n",
    "        right_pos = label_value_count[(1,0)]\n",
    "    else:\n",
    "        right_pos = 0\n",
    "        \n",
    "    if (0,0) in label_value_count:\n",
    "        right_neg = label_value_count[(0,0)]\n",
    "    else:\n",
    "        right_neg = 0\n",
    "        \n",
    "    # left_pos = label_value_count[(1,1)]\n",
    "    # left_neg = label_value_count[(0,1)]\n",
    "    # right_pos = label_value_count[(1,0)]\n",
    "    # right_neg = label_value_count[(0,0)]\n",
    "    \n",
    "    # calculate probabilities for left and right children\n",
    "    p_left = get_split_prob(left_pos, left_neg, total_count)\n",
    "    p_right = get_split_prob(right_pos, right_neg, total_count)\n",
    "    \n",
    "    # get left and right uncertainties\n",
    "    left_u = get_gini(left_pos, left_neg)\n",
    "    right_u = get_gini(right_pos, left_pos)\n",
    "    \n",
    "    # calculate benefit of split\n",
    "    benefit = initial_u - p_left*left_u - p_right*right_u\n",
    "    return benefit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "'cap-shape_s'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "# To get root node\n",
    "def get_best_split(train):\n",
    "    # Get list of feature names and list of class labels\n",
    "    feature_names = train.columns.to_list()\n",
    "    labels = train['class'].to_list()\n",
    "    # Create dictionary to store features and uncertainties\n",
    "    feature_uncertainty = {k : 0 for k in feature_names}\n",
    "\n",
    "    for feature_name in feature_names:\n",
    "        feature = train[feature_name].to_list()\n",
    "        feature_uncertainty[feature_name] = get_split_benefit(feature, labels)\n",
    "    # Extract feature that provides best benefit when split on\n",
    "    best_feature = max(feature_uncertainty, key=feature_uncertainty.get)\n",
    "    return best_feature\n",
    "    \n",
    "root = get_best_split(train)\n",
    "root\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}